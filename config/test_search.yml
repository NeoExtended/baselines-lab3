algorithm:
  name: "ppo"
  verbose: 10
  policy:
    name: ActorCriticCustomPolicy
    activation_fn: torch.nn.SELU
    normalize_images: true
    features_extractor_kwargs:
      activation: torch.nn.SELU
  tensorboard_log: true

env:
  name: "gym_maze:Maze0518Continuous-v0"
  wrappers:
    - stable_baselines3.common.atari_wrappers.MaxAndSkipEnv:
        skip: 4
    - gym.wrappers.ResizeObservation:
        shape: [ 84, 84 ]
  n_particles: 256
  normalize:
    norm_obs: false
    norm_reward: true
    precompute: true
    samples: 10000

meta:
  seed: 82
  n_timesteps: 5000000
  log_dir: "./logs/Labtest_Search"
  save_interval: 200000

search:
  n_timesteps: 4000000
  eval_method: "normal"
  n_test_episodes: 20
  n_trials: 40
  sampler: "tpe"
  pruner:
    method: "halving"
    min_resource: 800000
  env:
    n_envs:
      method: "categorical"
      choices: [8, 16, 32, 64]